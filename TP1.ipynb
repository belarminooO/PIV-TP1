{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "966c1c21",
   "metadata": {},
   "source": [
    "# Processamento de Imagem e Visão\n",
    "## Trabalho Prático 1\n",
    "### Alunos: Belarmino Sacate (52057) e Miguel Ferreira (51878)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5808c25a-020b-489c-b55b-1444a8621d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae27afed-adb3-4762-b5e8-6f16bd944c14",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17073a4",
   "metadata": {},
   "source": [
    "Esta função carrega todas as imagens presentes numa pasta expecífica. Ela percorre os ficheiros presentes e seleciona apenas as imagens, através das extenções jpg, png e jpeg.\n",
    "\n",
    "Cada imagem é guardada num dicionário onde a chave é o nome do ficheiro e o valor é a imagem em si. Assim, consegui-mos aceder a todas as imagens facilmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcac95fd-4979-4cc1-8dee-6ce8b21f7d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_imagens(pasta):\n",
    "\n",
    "    #dicionario para guardar as imagens\n",
    "    imagens = {}\n",
    "    \n",
    "    for nome_ficheiro in os.listdir(pasta):\n",
    "        if nome_ficheiro.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "            caminho = os.path.join(pasta, nome_ficheiro)\n",
    "            imagem = cv2.imread(caminho)\n",
    "            imagens[nome_ficheiro] = imagem\n",
    "    return imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c352e14",
   "metadata": {},
   "source": [
    "Nesta função a imagem é convertida do formato BGR (padrão usado pelo OpenCV), para o formato RGB. A função utilizada é cv2.cvtColor com a imagem e conversão pretendida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e309da7-6e65-44be-8b50-e09d70da0a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter_para_rgb(imagem):\n",
    "    return cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0464ba6e",
   "metadata": {},
   "source": [
    "A função refinar_mascara() usa vários operadores morfológicos para melhorar a qualidade da máscara binária gerada.\n",
    "\n",
    "É usado um elemento estruturante, ou seja, uma matriz pequena, com a sua forma e tamanho diferente, que determina a transformação efetuada.\n",
    "Foi escolhida a morfologia elíptica para detetar melhor as peças irregulares, mantendo o formato dos objetos. Apesar de a maior parte das peças serem retângulares, conseguiu-se ajustar os vários operadores de forma à não prejudicar estas peças.\n",
    "\n",
    "Em primeiro lugar, foi utilizado o MORPH_CLOSE, que é uma dilatação sucedida de uma erosão, com o objetivo de fechar pequenos buracos nas peças de lego. Estes buracos surgiram principalmente nas peças com a cor mais próxima do fundo azul. \n",
    "\n",
    "De seguida usou-se o MORPH_OPEN, ou seja, uma erosão seguida de uma dilatação, para remover pequenos defeitos nos contornos dos objetos ou falsos positivos detetados na imagem.\n",
    "\n",
    "Finalmente, foi feita uma erosão e dilatação com matrizes maiores com o objetivo de alimar todas as peças detetadas, suavizando os contornos, tornando-as mais fáceis de classificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc4b9435-96b1-4e92-8a5d-401f43c54390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refinar_mascara(mascara):\n",
    "    kernel1 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))\n",
    "    kernel2= cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    kernel3= cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (30, 30))\n",
    "    kernel4= cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))\n",
    "\n",
    "    mascara_close = cv2.morphologyEx(mascara, cv2.MORPH_CLOSE, kernel1)\n",
    "    mascara_open = cv2.morphologyEx(mascara_close, cv2.MORPH_OPEN, kernel2)\n",
    "    mascara_erosao = cv2.erode(mascara_open, kernel3)\n",
    "    mascara_final = cv2.dilate(mascara_erosao, kernel4)\n",
    "\n",
    "    return mascara_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f121b114",
   "metadata": {},
   "source": [
    "A função seguinte aplica a máscara binária gerada na imagem original através da operação bitwise. Nesta operação, os pixeis com valor 0, correspondentes à área preta na imagem, tornam-se pretos na imagem resultante. Os pixeis branco mantêm as cores da imagem originais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3b6c06b-77c1-4865-a051-84c100f593d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_mascara(imagem, mascara):\n",
    "    return cv2.bitwise_and(imagem, imagem, mask=mascara)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10ca89e",
   "metadata": {},
   "source": [
    "Este método é responsável por guardar as imagens no computador. Os resultados foram colocados na pasta do mesmo nome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62c56fe3-4b81-4aa9-b37c-9cc05b2bd59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gravar_imagem(imagem, nome_arquivo):\n",
    "    cv2.imwrite(nome_arquivo, imagem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d59575",
   "metadata": {},
   "source": [
    "Esta função cria uma máscara binária a partir dos limites de cores definidos. É utilizado o cv2.inRange(), que irá transformar as cores dentro do intervalo fornecido. Estas são transformadas em preto (0). As cores restantes que correspondem às peças ficam brancas (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25ebc0a0-7814-4ad1-86f4-27e5d90f7085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_mascara_por_cor(imagem_rgb, cor_inferior, cor_superior):\n",
    "    mascara = cv2.inRange(imagem_rgb, cor_inferior, cor_superior)\n",
    "    return mascara"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768436c9",
   "metadata": {},
   "source": [
    "Esta função permite ver a imagem numa janela à parte, esperando que uma tecla seja pressionada antes de fechar a própria janela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f251f70-7be3-452e-948b-d01c592f47d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exibir_imagem_cv2(titulo, imagem):\n",
    "    cv2.imshow(titulo, imagem)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e156aad6",
   "metadata": {},
   "source": [
    "Esta função calcula algumas propriedades para cada objeto identificado através do seu contorno. \n",
    "\n",
    "Primeiramente, obtemos a área de um objeto detetado na imagem, que pode ser uma peça de Lego ou não. De seguida, aplica-se o método minAreaRect() que gera o retângulo mínimo que consegue preencher o objeto todo. \n",
    "\n",
    "De seguida, é calculado o rácio entre a área real e o retângulo mínimo. Como o objetivo é identificar peças de Lego, as quais são retângulares, as duas áreas serão muito parecidas. Assim, conseguimos separar peças de Lego e outros objetos irregulares através da comparação destas duas áreas. \n",
    "\n",
    "Por fim, é calculada a razão entre a altura e largura da peça. Para garantir que as proporções possam ser comparadas corretamente, é usado um \"if\" que garante que o valor seja sempre maior ou igual a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6782069f-44ae-4bb1-8034-3384da86dc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracao_propriedades(contorno):\n",
    "    \n",
    "    #area do contorno da peça\n",
    "    area = cv2.contourArea(contorno)\n",
    "\n",
    "    #retangulo minimo\n",
    "    rect = cv2.minAreaRect(contorno)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int32(box)\n",
    "    \n",
    "    #racio de area\n",
    "    area_rect = cv2.contourArea(box)\n",
    "    if area_rect == 0:\n",
    "        racio = 0\n",
    "    else:\n",
    "        racio = (area / area_rect) * 100\n",
    "        \n",
    "    (x, y), (w, h), a = rect\n",
    "    \n",
    "    if min(w, h) == 0:\n",
    "        aspect_ratio = 0\n",
    "    else:\n",
    "        aspect_ratio = max(w, h) / min(w, h)\n",
    "\n",
    "    print(\"aspect_ratio:\", aspect_ratio)\n",
    "    \n",
    "    return area, aspect_ratio, box, racio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705204bd",
   "metadata": {},
   "source": [
    "A função classificacao_peca() usa as informações obtidas de cada contorno para identificar se o objeto é uma peça de Lego, pela sua forma retângular, bem como, classificá-las quanto à sua proporção. \n",
    "\n",
    "Os valores foram baseados nos resultados experimentais das imagens fornecidas. Além disso, foi adicionada uma verificação adicional com o objetivo de garantir que o objeto seja grande o suficiente para ser considerado uma peça de lego, evitando a classificação de alguns artefactos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21013822-b5cb-47eb-ad23-8a0771b24be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificacao_peca(area, aspect_ratio, racio, min_area):\n",
    "    \n",
    "    if area > min_area:\n",
    "\n",
    "        #area diferenca\n",
    "        if racio < 89:\n",
    "            return \"indefinido\"\n",
    "    \n",
    "        #aspect ratio\n",
    "        if 0.8 < aspect_ratio < 1.4:\n",
    "            return \"2x2\"\n",
    "        elif 1.8 < aspect_ratio < 2.6:\n",
    "            return\"2x4\"\n",
    "        elif 2.8 < aspect_ratio < 3.6:\n",
    "            return \"2x6\"\n",
    "        elif 3.8 < aspect_ratio < 5.1:\n",
    "            return \"2x8\"\n",
    "        else:\n",
    "            return \"indefinido\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a7aa2a",
   "metadata": {},
   "source": [
    "# EXECUÇÃO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cf6630",
   "metadata": {},
   "source": [
    "Para facilitar a execução das funções, seguimos a dica dada pelo professor, que consistia em carregar todas as imagens de teste e armazená-las em um dicionário, evitando assim a necessidade de, sempre que quiséssemos testar o classificador em uma imagem, ter que carregá-las novamente.\n",
    "\n",
    "temos especificado o caminho até a pasta imagens (pasta_treino), que contém as imagens de treino fornecidas e que, por sua vez, são carregadas pela função carregar_imagens.\n",
    "\n",
    "Para tornar a execução mais prática, fizemos um ciclo for para percorrer todas as imagens carregadas anteriormente. criamos uma tambem a variável \"nome\" para obter o nome da imagem correspondente à iteração em que o \"for\" estiver, permitindo assim acessar o conteúdo dessa imagem e armazená-lo na variável \"img\".\n",
    "\n",
    "Apos o armazenamento do conteudo da imagem seguimos para a conversao da mesma, mudando-a de BGR para RGB, essa conversao foi um ponto que o professor acabou por especificar em uma das aulas praticas\n",
    "\n",
    "depois de termos convertido a imagem, o nosso proximo passo foi a criacao de intervalos inferiores e superiores referentes a cor azul(fundo_inferior e fundo_superior) para podermos posteormente fazer a aplicao da mascara (aplicar_mascara), retirando assim o fundo azul.\n",
    "\n",
    "Para o conseguirmos dectetar os contornos dos objectos usamos a funcao findContours especificamos os seguintes parametros:\n",
    "mascara_refinada - mascara melhorada atraves dos operadores morfogicos\n",
    "cv2.RETR_EXTERNAL - refere a identificacao de contornos externos\n",
    "cv2.CHAIN_APPROX_SIMPLE - armazena apenas os pontos essenciais\n",
    "\n",
    "E para desenharmos os contornos usamos a funcao cv2.drawContours() espificiando os seguintes parametros:\n",
    "imagem_com_contornos - copia da imagem orignal onde os contornos serao desenhados\n",
    "contornos - É a lista de contornos retornada por cv2.findContours.\n",
    "-1 - serve para indicar que quer desenhar todos os contornos do array contornos.\n",
    "(0, 255, 0) - cor dos contornos que serao desenhados\n",
    "2 - espessura da linha\n",
    "\n",
    "\n",
    "Tendo completado este passo, avancamos finalmente para a extracao de caracteristicas e classificao.\n",
    "\n",
    "iniciamos um novo ciclo for para percorrer cada contorno encontrado na mascara.\n",
    "Dentro deste ciclo, começamos por calcular um retângulo delimitador(bounding box) para cada objecto. (x, y, w, h = cv2.boundingRect(contorno))\n",
    "\n",
    "onde:\n",
    "x e y - representam as coordenadas do canto superior esquerdo do objecto.\n",
    "w e h - correspondem à largura e altura.\n",
    "\n",
    "Criamos também uma variável \"min_area\", utilizada para evitar que pequenas imperfeições do fundo sejam classificadas como peças, definimos tambem uma variável margem, usada para evitar que peças encostadas às bordas da imagem sejam consideradas. Essa foi a solução que encontramos para garantir que a peça de lego cinzenta presente na imagem “lego30” fosse ignorada.\n",
    "\n",
    "A variável \"margem\" é usada em conjunto com as variáveis \"image_h\" e \"image_w\", que armazenam a altura e a largura da imagem. usamos essas variáveis ajudaram-nos a verificar se os lados dos contornos estavam muito próximos das bordas da imagem. Caso não estejam, o objeto segue para a extração das propriedades e  classificação, caso contrário, o objecto é ignorado.\n",
    "\n",
    "Após a classificação, armazenamos os resultados (tipo, área e aspect_ratio) dentro do array pecas_classificadas, esse array armazena todas as informações das peças apos a classificao. Por fim, escrevemos na imagem os tipos de peças encontrados e gravamos as imagens resultantes na pasta resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efc52dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 imagens carregadas.\n"
     ]
    }
   ],
   "source": [
    "pasta_treino = \"./imagens\"\n",
    "imagens = carregar_imagens(pasta_treino)\n",
    "print(len(imagens), \"imagens carregadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60c1906c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0185459462757018\n",
      "aspect_ratio: 1.6981133559283204\n",
      "aspect_ratio: 2.2287120806750362\n",
      "aspect_ratio: 1.6901095462486133\n",
      "aspect_ratio: 2.262927433253323\n",
      "aspect_ratio: 2.1747574239140945\n",
      "aspect_ratio: 4.72916654163348\n",
      "aspect_ratio: 1.0341685015748046\n",
      "aspect_ratio: 1.0486331140075251\n",
      "[('2x2', 6258.5, 1.0185459462757018), ('indefinido', 14304.5, 1.6981133559283204), ('2x4', 11897.0, 2.2287120806750362), ('indefinido', 9194.5, 1.6901095462486133), ('2x4', 11580.5, 2.262927433253323), ('2x4', 12463.5, 2.1747574239140945), ('2x8', 23246.0, 4.72916654163348), ('2x2', 6614.0, 1.0341685015748046), ('2x2', 6092.0, 1.0486331140075251)]\n",
      "aspect_ratio: 2.2030567736474285\n",
      "aspect_ratio: 1.4093438095871682\n",
      "aspect_ratio: 2.3090184987144515\n",
      "aspect_ratio: 4.855026217104629\n",
      "aspect_ratio: 1.0203001179796636\n",
      "aspect_ratio: 1.0575540322930164\n",
      "[('2x4', 11884.5, 2.2030567736474285), ('indefinido', 7019.0, 1.4093438095871682), ('2x4', 12058.5, 2.3090184987144515), ('2x8', 22721.5, 4.855026217104629), ('2x2', 6434.0, 1.0203001179796636), ('2x2', 6033.5, 1.0575540322930164)]\n",
      "aspect_ratio: 1.0110100879359758\n",
      "aspect_ratio: 2.203319481563745\n",
      "aspect_ratio: 1.0285156086741853\n",
      "[('2x2', 5307.0, 1.0110100879359758), ('2x4', 11765.5, 2.203319481563745), ('2x2', 5572.5, 1.0285156086741853)]\n",
      "aspect_ratio: 2.2434780594089414\n",
      "aspect_ratio: 2.0978173322114304\n",
      "aspect_ratio: 3.3866671974050853\n",
      "aspect_ratio: 4.666221242589581\n",
      "[('2x4', 11538.0, 2.2434780594089414), ('2x4', 11369.0, 2.0978173322114304), ('2x6', 19541.0, 3.3866671974050853), ('2x8', 23734.5, 4.666221242589581)]\n",
      "aspect_ratio: 1.0714285714285714\n",
      "aspect_ratio: 1.90625\n",
      "aspect_ratio: 2.4389900175658945\n",
      "aspect_ratio: 4.525254370481916\n",
      "[(None, 172.5, 1.0714285714285714), (None, 1229.0, 1.90625), ('2x4', 11236.5, 2.4389900175658945), ('2x8', 23116.0, 4.525254370481916)]\n",
      "aspect_ratio: 2.148955480025358\n",
      "aspect_ratio: 4.24018011872401\n",
      "aspect_ratio: 2.230873262225251\n",
      "[('2x4', 12358.5, 2.148955480025358), ('2x8', 24332.5, 4.24018011872401), ('2x4', 11348.0, 2.230873262225251)]\n",
      "aspect_ratio: 1.68383014868785\n",
      "aspect_ratio: 1.5100146299713115\n",
      "aspect_ratio: 1.4289730860019796\n",
      "[('indefinido', 14191.0, 1.68383014868785), ('indefinido', 8882.5, 1.5100146299713115), ('indefinido', 7393.0, 1.4289730860019796)]\n",
      "aspect_ratio: 2.25\n",
      "aspect_ratio: 2.248934105351571\n",
      "aspect_ratio: 3.1593424258480223\n",
      "aspect_ratio: 1.5541284010455134\n",
      "[('2x4', 11598.0, 2.25), ('2x4', 11495.0, 2.248934105351571), ('2x6', 20804.0, 3.1593424258480223), ('indefinido', 13555.0, 1.5541284010455134)]\n",
      "aspect_ratio: 1.0649418201685714\n",
      "aspect_ratio: 2.2186982378563367\n",
      "aspect_ratio: 3.5647978047869007\n",
      "aspect_ratio: 4.557894178928544\n",
      "[('2x2', 5838.5, 1.0649418201685714), ('2x4', 12034.5, 2.2186982378563367), ('2x6', 17679.0, 3.5647978047869007), ('2x8', 24887.0, 4.557894178928544)]\n",
      "aspect_ratio: 1.0167714675304598\n",
      "aspect_ratio: 1.010322978111758\n",
      "aspect_ratio: 1.0133333333333334\n",
      "aspect_ratio: 1.0194385409337563\n",
      "[('2x2', 5260.0, 1.0167714675304598), ('2x2', 5571.5, 1.010322978111758), ('2x2', 5630.0, 1.0133333333333334), ('2x2', 5580.5, 1.0194385409337563)]\n",
      "aspect_ratio: 2.250608475590586\n",
      "aspect_ratio: 2.168141671212489\n",
      "aspect_ratio: 2.1481483257546423\n",
      "aspect_ratio: 2.1950657110486973\n",
      "[('2x4', 11768.0, 2.250608475590586), ('2x4', 12042.5, 2.168141671212489), ('2x4', 12267.0, 2.1481483257546423), ('2x4', 12429.5, 2.1950657110486973)]\n",
      "aspect_ratio: 4.780118350222553\n",
      "[('2x8', 23416.5, 4.780118350222553)]\n",
      "aspect_ratio: 2.3055873360071\n",
      "aspect_ratio: 1.0052701794823504\n",
      "aspect_ratio: 1.971682173160881\n",
      "aspect_ratio: 3.497307030427186\n",
      "aspect_ratio: 3.304785594022033\n",
      "[('2x4', 12163.5, 2.3055873360071), ('2x2', 5714.0, 1.0052701794823504), ('indefinido', 5881.5, 1.971682173160881), ('2x6', 17517.5, 3.497307030427186), ('2x6', 19278.0, 3.304785594022033)]\n",
      "aspect_ratio: 1.0429118164910252\n",
      "aspect_ratio: 2.2223235862766613\n",
      "aspect_ratio: 2.0001678358790653\n",
      "aspect_ratio: 3.3086393747685663\n",
      "[('2x2', 5990.5, 1.0429118164910252), ('2x4', 11979.0, 2.2223235862766613), ('indefinido', 5836.0, 2.0001678358790653), ('2x6', 19448.5, 3.3086393747685663)]\n"
     ]
    }
   ],
   "source": [
    "nomes = list(imagens.keys())\n",
    "\n",
    "for i in range(len(imagens)):\n",
    "    #selecao da imagem\n",
    "    nome = nomes[i]\n",
    "    img = imagens[nome] \n",
    "\n",
    "    #conversao para rgb\n",
    "    rgb_img = converter_para_rgb(img)\n",
    "\n",
    "    #definicao dos intervalos de cor do fundo\n",
    "    fundo_inferior = np.array([90, 0, 0])      \n",
    "    fundo_superior = np.array([255, 255, 255])\n",
    "\n",
    "    #criacao e aplocacao da mascara\n",
    "    mascara_fundo = criar_mascara_por_cor(rgb_img, fundo_inferior, fundo_superior)\n",
    "    mascara_refinada = refinar_mascara(mascara_fundo)\n",
    "    imagem_isolada = aplicar_mascara(rgb_img, mascara_refinada)\n",
    "\n",
    "\n",
    "    #desenho dos contornos dos objectos\n",
    "    contornos, _ = cv2.findContours(mascara_refinada,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    #desenho dos contornos na imagem original\n",
    "    imagem_com_contornos = img.copy()\n",
    "    cv2.drawContours(imagem_com_contornos, contornos, -1, (0, 255, 0), 2)\n",
    "    \n",
    "\n",
    "    pecas_classificadas = []\n",
    "\n",
    "    image_h = img.shape[0]\n",
    "    image_w = img.shape[1]\n",
    "\n",
    "    min_area = 1500\n",
    "\n",
    "    for contorno in contornos:\n",
    "        \n",
    "        x, y, w, h = cv2.boundingRect(contorno)\n",
    "        margem = 10\n",
    "        if x <= margem or y <= margem or x + w >= image_w - margem or y + h >= image_h - margem:\n",
    "            continue\n",
    "        else:\n",
    "            area, aspect_ratio, box, racio = extracao_propriedades(contorno)\n",
    "            cv2.drawContours(imagem_com_contornos, [box], 0, (255, 0, 0), 2)\n",
    "\n",
    "            tipo = classificacao_peca(area, aspect_ratio, racio, min_area)\n",
    "\n",
    "            pecas_classificadas.append((tipo, area, aspect_ratio))\n",
    "\n",
    "            x, y, w, h = cv2.boundingRect(contorno)\n",
    "            posicao_texto = (x, y)\n",
    "            posicao_texto_2 = (x, y - 50)  \n",
    "\n",
    "            cv2.putText(imagem_com_contornos, tipo, posicao_texto, cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), 2)\n",
    "            #if area > min_area:\n",
    "                #cv2.putText(imagem_com_contornos, str(aspect_ratio), posicao_texto_2, cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2)\n",
    "\n",
    "    gravar_imagem(cv2.cvtColor(mascara_refinada, cv2.COLOR_GRAY2BGR), f\"resultados/mascara_refinada_{i}.jpg\")\n",
    "    gravar_imagem(cv2.cvtColor(imagem_isolada, cv2.COLOR_RGB2BGR), f\"resultados/imagem_isolada_{i}.jpg\")\n",
    "    gravar_imagem(imagem_com_contornos, f\"resultados/imagem_com_contornos_{i}.jpg\")\n",
    "\n",
    "    print(pecas_classificadas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
